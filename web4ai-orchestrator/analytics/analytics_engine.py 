# analytics/analytics_engine.py - Advanced Analytics and Reporting
"""
Advanced analytics and reporting engine for Web4AI Orchestrator
Provides insights, predictions, and comprehensive reporting capabilities
"""

import numpy as np
import pandas as pd
import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import defaultdict
import statistics
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
import base64

# Machine learning imports (optional)
try:
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    from sklearn.preprocessing import StandardScaler
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class AnalyticsReport:
    """Analytics report structure"""
    report_id: str
    report_type: str
    title: str
    summary: Dict[str, Any]
    sections: List[Dict[str, Any]]
    charts: List[Dict[str, Any]]
    recommendations: List[str]
    generated_at: datetime
    time_period: Dict[str, datetime]
    metadata: Dict[str, Any]

class AnalyticsEngine:
    """Main analytics engine"""
    
    def __init__(self, orchestrator, database_manager):
        self.orchestrator = orchestrator
        self.db = database_manager
        self.reports_cache = {}
        
        # Analytics modules
        self.performance_analyzer = PerformanceAnalyzer(orchestrator, database_manager)
        self.usage_analyzer = UsageAnalyzer(orchestrator, database_manager)
        self.cost_analyzer = CostAnalyzer(orchestrator, database_manager)
        self.predictive_analyzer = PredictiveAnalyzer(orchestrator, database_manager) if ML_AVAILABLE else None
        
    def generate_comprehensive_report(self, days: int = 7) -> AnalyticsReport:
        """Generate comprehensive analytics report"""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)
        
        report_id = f"comprehensive_{int(end_time.timestamp())}"
        
        # Collect data from all analyzers
        performance_data = self.performance_analyzer.analyze_performance(start_time, end_time)
        usage_data = self.usage_analyzer.analyze_usage(start_time, end_time)
        cost_data = self.cost_analyzer.analyze_costs(start_time, end_time)
        
        # Generate summary
        summary = {
            'time_period_days': days,
            'total_tasks': usage_data.get('total_tasks', 0),
            'success_rate': performance_data.get('success_rate', 0),
            'avg_response_time': performance_data.get('avg_response_time', 0),
            'peak_utilization': usage_data.get('peak_utilization', 0),
            'total_cost': cost_data.get('total_cost', 0),
            'active_nodes': len([n for n in self.orchestrator.nodes.values() if n.status.value == 'active'])
        }
        
        # Create report sections
        sections = [
            self._create_executive_summary(summary, performance_data, usage_data),
            self._create_performance_section(performance_data),
            self._create_usage_section(usage_data),
            self._create_cost_section(cost_data),
            self._create_node_analysis_section(),
            self._create_trend_analysis_section(start_time, end_time)
        ]
        
        # Generate charts
        charts = self._generate_report_charts(performance_data, usage_data, cost_data)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(performance_data, usage_data, cost_data)
        
        # Add predictive analysis if available
        if self.predictive_analyzer:
            prediction_data = self.predictive_analyzer.generate_predictions(start_time, end_time)
            sections.append(self._create_predictions_section(prediction_data))
            recommendations.extend(prediction_data.get('recommendations', []))
        
        report = AnalyticsReport(
            report_id=report_id,
            report_type="comprehensive",
            title=f"Web4AI Orchestrator Analytics Report - {days} Days",
            summary=summary,
            sections=sections,
            charts=charts,
            recommendations=recommendations,
            generated_at=end_time,
            time_period={'start': start_time, 'end': end_time},
            metadata={'days': days, 'nodes_analyzed': len(self.orchestrator.nodes)}
        )
        
        # Cache report
        self.reports_cache[report_id] = report
        
        return report
    
    def _create_executive_summary(self, summary: Dict, performance_data: Dict, usage_data: Dict) -> Dict[str, Any]:
        """Create executive summary section"""
        return {
            'title': 'Executive Summary',
            'type': 'summary',
            'content': {
                'key_metrics': [
                    {'label': 'Total Tasks Processed', 'value': f"{summary['total_tasks']:,}"},
                    {'label': 'Success Rate', 'value': f"{summary['success_rate']:.1%}"},
                    {'label': 'Average Response Time', 'value': f"{summary['avg_response_time']:.1f}ms"},
                    {'label': 'Peak Utilization', 'value': f"{summary['peak_utilization']:.1%}"},
                    {'label': 'Active Nodes', 'value': summary['active_nodes']}
                ],
                'highlights': [
                    f"Processed {summary['total_tasks']:,} tasks with {summary['success_rate']:.1%} success rate",
                    f"Average response time of {summary['avg_response_time']:.1f}ms",
                    f"Peak utilization reached {summary['peak_utilization']:.1%}",
                    f"Currently managing {summary['active_nodes']} active nodes"
                ],
                'status': self._determine_overall_status(summary)
            }
        }
    
    def _create_performance_section(self, performance_data: Dict) -> Dict[str, Any]:
        """Create performance analysis section"""
        return {
            'title': 'Performance Analysis',
            'type': 'performance',
            'content': {
                'metrics': performance_data,
                'insights': [
                    f"Task completion rate: {performance_data.get('completion_rate', 0):.1%}",
                    f"Average task execution time: {performance_data.get('avg_execution_time', 0):.1f}s",
                    f"P95 response time: {performance_data.get('p95_response_time', 0):.1f}ms",
                    f"Error rate: {performance_data.get('error_rate', 0):.1%}"
                ],
                'performance_score': self._calculate_performance_score(performance_data)
            }
        }
    
    def _create_usage_section(self, usage_data: Dict) -> Dict[str, Any]:
        """Create usage analysis section"""
        return {
            'title': 'Usage Patterns',
            'type': 'usage',
            'content': {
                'patterns': usage_data,
                'insights': [
                    f"Peak usage: {usage_data.get('peak_hour', 'Unknown')}:00",
                    f"Most common task type: {usage_data.get('top_task_type', 'Unknown')}",
                    f"Average daily tasks: {usage_data.get('avg_daily_tasks', 0):.0f}",
                    f"Resource utilization trend: {usage_data.get('utilization_trend', 'Stable')}"
                ]
            }
        }
    
    def _create_cost_section(self, cost_data: Dict) -> Dict[str, Any]:
        """Create cost analysis section"""
        return {
            'title': 'Cost Analysis',
            'type': 'cost',
            'content': {
                'costs': cost_data,
                'insights': [
                    f"Total cost: ${cost_data.get('total_cost', 0):.2f}",
                    f"Cost per task: ${cost_data.get('cost_per_task', 0):.4f}",
                    f"Most expensive resource: {cost_data.get('top_cost_driver', 'Unknown')}",
                    f"Cost trend: {cost_data.get('cost_trend', 'Stable')}"
                ]
            }
        }
    
    def _create_node_analysis_section(self) -> Dict[str, Any]:
        """Create node analysis section"""
        nodes_data = []
        
        for node_id, node in self.orchestrator.nodes.items():
            nodes_data.append({
                'node_id': node_id,
                'status': node.status.value,
                'cpu_usage': node.cpu_usage,
                'memory_usage': node.memory_usage,
                'load_score': node.load_score,
                'reliability_score': node.reliability_score,
                'tasks_completed': node.tasks_completed,
                'tasks_failed': node.tasks_failed
            })
        
        # Calculate node statistics
        if nodes_data:
            avg_cpu = statistics.mean([n['cpu_usage'] for n in nodes_data])
            avg_memory = statistics.mean([n['memory_usage'] for n in nodes_data])
            total_tasks = sum([n['tasks_completed'] for n in nodes_data])
        else:
            avg_cpu = avg_memory = total_tasks = 0
        
        return {
            'title': 'Node Analysis',
            'type': 'nodes',
            'content': {
                'node_count': len(nodes_data),
                'avg_cpu_usage': avg_cpu,
                'avg_memory_usage': avg_memory,
                'total_tasks_completed': total_tasks,
                'nodes': nodes_data,
                'insights': [
                    f"Managing {len(nodes_data)} nodes",
                    f"Average CPU usage: {avg_cpu:.1f}%",
                    f"Average memory usage: {avg_memory:.1f}%",
                    f"Total tasks completed: {total_tasks:,}"
                ]
            }
        }
    
    def _create_trend_analysis_section(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Create trend analysis section"""
        # Get historical metrics
        metrics = self._get_historical_metrics(start_time, end_time)
        
        trends = {
            'utilization_trend': self._calculate_trend(metrics.get('utilization', [])),
            'throughput_trend': self._calculate_trend(metrics.get('throughput', [])),
            'error_rate_trend': self._calculate_trend(metrics.get('error_rate', [])),
            'response_time_trend': self._calculate_trend(metrics.get('response_time', []))
        }
        
        return {
            'title': 'Trend Analysis',
            'type': 'trends',
            'content': {
                'trends': trends,
                'insights': [
                    f"Utilization trend: {trends['utilization_trend']}",
                    f"Throughput trend: {trends['throughput_trend']}",
                    f"Error rate trend: {trends['error_rate_trend']}",
                    f"Response time trend: {trends['response_time_trend']}"
                ]
            }
        }
    
    def _create_predictions_section(self, prediction_data: Dict) -> Dict[str, Any]:
        """Create predictions section"""
        return {
            'title': 'Predictive Analysis',
            'type': 'predictions',
            'content': {
                'predictions': prediction_data,
                'insights': [
                    f"Predicted load for next 24h: {prediction_data.get('next_24h_load', 0):.1%}",
                    f"Estimated scaling needs: {prediction_data.get('scaling_recommendation', 'No change')}",
                    f"Resource optimization potential: {prediction_data.get('optimization_potential', 0):.1%}",
                    f"Confidence level: {prediction_data.get('confidence', 0):.1%}"
                ]
            }
        }
    
    def _generate_report_charts(self, performance_data: Dict, usage_data: Dict, cost_data: Dict) -> List[Dict[str, Any]]:
        """Generate charts for the report"""
        charts = []
        
        # Performance over time chart
        if 'performance_history' in performance_data:
            chart_data = self._create_performance_chart(performance_data['performance_history'])
            charts.append({
                'title': 'Performance Over Time',
                'type': 'line_chart',
                'data': chart_data
            })
        
        # Usage patterns chart
        if 'hourly_usage' in usage_data:
            chart_data = self._create_usage_chart(usage_data['hourly_usage'])
            charts.append({
                'title': 'Hourly Usage Patterns',
                'type': 'bar_chart',
                'data': chart_data
            })
        
        # Cost breakdown chart
        if 'cost_breakdown' in cost_data:
            chart_data = self._create_cost_chart(cost_data['cost_breakdown'])
            charts.append({
                'title': 'Cost Breakdown',
                'type': 'pie_chart',
                'data': chart_data
            })
        
        return charts
    
    def _generate_recommendations(self, performance_data: Dict, usage_data: Dict, cost_data: Dict) -> List[str]:
        """Generate actionable recommendations"""
        recommendations = []
        
        # Performance recommendations
        if performance_data.get('error_rate', 0) > 0.05:  # 5% error rate
            recommendations.append(
                "High error rate detected. Review task failures and node health."
            )
        
        if performance_data.get('avg_response_time', 0) > 2000:  # 2 seconds
            recommendations.append(
                "High response times detected. Consider adding more nodes or optimizing task processing."
            )
        
        # Usage recommendations
        peak_utilization = usage_data.get('peak_utilization', 0)
        if peak_utilization > 0.9:
            recommendations.append(
                "Network utilization is consistently high. Consider implementing auto-scaling."
            )
        elif peak_utilization < 0.3:
            recommendations.append(
                "Network utilization is low. Consider scaling down to reduce costs."
            )
        
        # Cost recommendations
        cost_per_task = cost_data.get('cost_per_task', 0)
        if cost_per_task > 0.10:  # $0.10 per task
            recommendations.append(
                "Cost per task is high. Review resource allocation and node efficiency."
            )
        
        # Node recommendations
        active_nodes = len([n for n in self.orchestrator.nodes.values() if n.status.value == 'active'])
        if active_nodes < 2:
            recommendations.append(
                "Consider adding more nodes for better fault tolerance and load distribution."
            )
        
        return recommendations
    
    def export_report_pdf(self, report: AnalyticsReport) -> bytes:
        """Export report as PDF"""
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.lib import colors
            from io import BytesIO
            
            buffer = BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=A4)
            styles = getSampleStyleSheet()
            
            # Build PDF content
            story = []
            
            # Title
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Title'],
                fontSize=24,
                textColor=colors.darkblue
            )
            story.append(Paragraph(report.title, title_style))
            story.append(Spacer(1, 12))
            
            # Summary
            story.append(Paragraph("Executive Summary", styles['Heading1']))
            for section in report.sections:
                if section['type'] == 'summary':
                    for highlight in section['content']['highlights']:
                        story.append(Paragraph(f"• {highlight}", styles['Normal']))
                    break
            
            story.append(Spacer(1, 12))
            
            # Key metrics table
            story.append(Paragraph("Key Metrics", styles['Heading2']))
            
            for section in report.sections:
                if section['type'] == 'summary':
                    metrics_data = [['Metric', 'Value']]
                    for metric in section['content']['key_metrics']:
                        metrics_data.append([metric['label'], metric['value']])
                    
                    table = Table(metrics_data)
                    table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                        ('FONTSIZE', (0, 0), (-1, 0), 14),
                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                        ('GRID', (0, 0), (-1, -1), 1, colors.black)
                    ]))
                    story.append(table)
                    break
            
            # Recommendations
            story.append(Spacer(1, 12))
            story.append(Paragraph("Recommendations", styles['Heading2']))
            for i, rec in enumerate(report.recommendations, 1):
                story.append(Paragraph(f"{i}. {rec}", styles['Normal']))
            
            # Build PDF
            doc.build(story)
            buffer.seek(0)
            
            return buffer.getvalue()
            
        except ImportError:
            logger.error("reportlab not available for PDF export")
            return b"PDF export requires reportlab library"
    
    def export_report_html(self, report: AnalyticsReport) -> str:
        """Export report as HTML"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>{title}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ background: #f0f0f0; padding: 20px; border-radius: 8px; }}
                .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007cba; }}
                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: white; border: 1px solid #ddd; border-radius: 4px; }}
                .recommendations {{ background: #fff3cd; padding: 15px; border-radius: 4px; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{title}</h1>
                <p>Generated: {generated_at}</p>
                <p>Period: {time_period}</p>
            </div>
            
            {sections_html}
            
            <div class="recommendations">
                <h2>Recommendations</h2>
                <ul>
                    {recommendations_html}
                </ul>
            </div>
        </body>
        </html>
        """
        
        # Generate sections HTML
        sections_html = ""
        for section in report.sections:
            sections_html += f"""
            <div class="section">
                <h2>{section['title']}</h2>
                {self._section_to_html(section)}
            </div>
            """
        
        # Generate recommendations HTML
        recommendations_html = ""
        for rec in report.recommendations:
            recommendations_html += f"<li>{rec}</li>\n"
        
        return html_template.format(
            title=report.title,
            generated_at=report.generated_at.strftime('%Y-%m-%d %H:%M:%S'),
            time_period=f"{report.time_period['start'].strftime('%Y-%m-%d')} to {report.time_period['end'].strftime('%Y-%m-%d')}",
            sections_html=sections_html,
            recommendations_html=recommendations_html
        )

class PerformanceAnalyzer:
    """Performance analysis module"""
    
    def __init__(self, orchestrator, database_manager):
        self.orchestrator = orchestrator
        self.db = database_manager
    
    def analyze_performance(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Analyze performance metrics"""
        # Get completed and failed tasks
        completed_tasks = self.db.get_tasks_by_status('completed', limit=10000)
        failed_tasks = self.db.get_tasks_by_status('failed', limit=1000)
        
        # Filter by time range
        completed_tasks = [t for t in completed_tasks if self._in_time_range(t, start_time, end_time)]
        failed_tasks = [t for t in failed_tasks if self._in_time_range(t, start_time, end_time)]
        
        total_tasks = len(completed_tasks) + len(failed_tasks)
        
        if total_tasks == 0:
            return {'success_rate': 1.0, 'avg_response_time': 0, 'total_tasks': 0}
        
        # Calculate metrics
        success_rate = len(completed_tasks) / total_tasks
        
        execution_times = [t.get('execution_time', 0) for t in completed_tasks if t.get('execution_time')]
        avg_execution_time = statistics.mean(execution_times) if execution_times else 0
        
        # Response time (creation to completion)
        response_times = []
        for task in completed_tasks:
            created_at = self._parse_datetime(task.get('created_at'))
            completed_at = self._parse_datetime(task.get('completed_at'))
            if created_at and completed_at:
                response_time = (completed_at - created_at).total_seconds() * 1000  # ms
                response_times.append(response_time)
        
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = np.percentile(response_times, 95) if response_times else 0
        
        return {
            'total_tasks': total_tasks,
            'success_rate': success_rate,
            'error_rate': 1 - success_rate,
            'completion_rate': success_rate,
            'avg_execution_time': avg_execution_time,
            'avg_response_time': avg_response_time,
            'p95_response_time': p95_response_time,
            'performance_history': self._get_performance_history(start_time, end_time)
        }
    
    def _in_time_range(self, task: Dict, start_time: datetime, end_time: datetime) -> bool:
        """Check if task is in time range"""
        created_at = self._parse_datetime(task.get('created_at'))
        return created_at and start_time <= created_at <= end_time
    
    def _parse_datetime(self, dt_str: Any) -> Optional[datetime]:
        """Parse datetime string"""
        if isinstance(dt_str, datetime):
            return dt_str
        if isinstance(dt_str, str):
            try:
                return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
            except:
                pass
        return None
    
    def _get_performance_history(self, start_time: datetime, end_time: datetime) -> List[Dict[str, Any]]:
        """Get performance history over time"""
        # This would typically get metrics from the monitoring system
        # For now, return sample data
        history = []
        current = start_time
        
        while current < end_time:
            history.append({
                'timestamp': current.isoformat(),
                'success_rate': 0.95 + (np.random.random() - 0.5) * 0.1,
                'avg_response_time': 1500 + (np.random.random() - 0.5) * 500,
                'throughput': 50 + (np.random.random() - 0.5) * 20
            })
            current += timedelta(hours=1)
        
        return history

class UsageAnalyzer:
    """Usage pattern analysis module"""
    
    def __init__(self, orchestrator, database_manager):
        self.orchestrator = orchestrator
        self.db = database_manager
    
    def analyze_usage(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Analyze usage patterns"""
        # Get all tasks in time range
        all_tasks = []
        for status in ['completed', 'failed', 'running']:
            tasks = self.db.get_tasks_by_status(status, limit=10000)
            all_tasks.extend([t for t in tasks if self._in_time_range(t, start_time, end_time)])
        
        if not all_tasks:
            return {'total_tasks': 0, 'peak_utilization': 0}
        
        # Analyze patterns
        hourly_usage = defaultdict(int)
        task_types = defaultdict(int)
        daily_tasks = defaultdict(int)
        
        for task in all_tasks:
            created_at = self._parse_datetime(task.get('created_at'))
            if created_at:
                hourly_usage[created_at.hour] += 1
                daily_tasks[created_at.date()] += 1
                task_types[task.get('task_type', 'unknown')] += 1
        
        # Find peak hour
        peak_hour = max(hourly_usage.items(), key=lambda x: x[1])[0] if hourly_usage else 0
        
        # Calculate utilization (simplified)
        current_utilization = self.orchestrator.network_metrics.get('network_utilization', 0)
        peak_utilization = max(current_utilization * 1.2, current_utilization)
        
        # Top task type
        top_task_type = max(task_types.items(), key=lambda x: x[1])[0] if task_types else 'unknown'
        
        # Average daily tasks
        avg_daily_tasks = statistics.mean(daily_tasks.values()) if daily_tasks else 0
        
        return {
            'total_tasks': len(all_tasks),
            'peak_hour': peak_hour,
            'peak_utilization': peak_utilization,
            'top_task_type': top_task_type,
            'avg_daily_tasks': avg_daily_tasks,
            'task_type_distribution': dict(task_types),
            'hourly_usage': dict(hourly_usage),
            'utilization_trend': 'Increasing'  # Simplified
        }
    
    def _in_time_range(self, task: Dict, start_time: datetime, end_time: datetime) -> bool:
        """Check if task is in time range"""
        created_at = self._parse_datetime(task.get('created_at'))
        return created_at and start_time <= created_at <= end_time
    
    def _parse_datetime(self, dt_str: Any) -> Optional[datetime]:
        """Parse datetime string"""
        if isinstance(dt_str, datetime):
            return dt_str
        if isinstance(dt_str, str):
            try:
                return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
            except:
                pass
        return None

class CostAnalyzer:
    """Cost analysis module"""
    
    def __init__(self, orchestrator, database_manager):
        self.orchestrator = orchestrator
        self.db = database_manager
        
        # Cost models (these would be configurable)
        self.cost_per_node_hour = 0.50  # $0.50 per node per hour
        self.cost_per_task = 0.001  # $0.001 per task
        self.cost_per_gb_storage = 0.10  # $0.10 per GB per month
    
    def analyze_costs(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Analyze costs"""
        time_hours = (end_time - start_time).total_seconds() / 3600
        
        # Calculate node costs
        active_nodes = len([n for n in self.orchestrator.nodes.values() if n.status.value == 'active'])
        node_cost = active_nodes * self.cost_per_node_hour * time_hours
        
        # Calculate task costs
        all_tasks = []
        for status in ['completed', 'failed']:
            tasks = self.db.get_tasks_by_status(status, limit=10000)
            all_tasks.extend([t for t in tasks if self._in_time_range(t, start_time, end_time)])
        
        task_cost = len(all_tasks) * self.cost_per_task
        
        # Calculate storage costs (simplified)
        storage_cost = 0.10 * time_hours / (24 * 30)  # Approximate monthly cost
        
        total_cost = node_cost + task_cost + storage_cost
        cost_per_task = total_cost / len(all_tasks) if all_tasks else 0
        
        return {
            'total_cost': total_cost,
            'node_cost': node_cost,
            'task_cost': task_cost,
            'storage_cost': storage_cost,
            'cost_per_task': cost_per_task,
            'cost_breakdown': {
                'Compute': node_cost,
                'Tasks': task_cost,
                'Storage': storage_cost
            },
            'top_cost_driver': 'Compute' if node_cost > task_cost else 'Tasks',
            'cost_trend': 'Stable'  # Simplified
        }
    
    def _in_time_range(self, task: Dict, start_time: datetime, end_time: datetime) -> bool:
        """Check if task is in time range"""
        created_at = self._parse_datetime(task.get('created_at'))
        return created_at and start_time <= created_at <= end_time
    
    def _parse_datetime(self, dt_str: Any) -> Optional[datetime]:
        """Parse datetime string"""
        if isinstance(dt_str, datetime):
            return dt_str
        if isinstance(dt_str, str):
            try:
                return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
            except:
                pass
        return None

class PredictiveAnalyzer:
    """Predictive analysis using machine learning"""
    
    def __init__(self, orchestrator, database_manager):
        self.orchestrator = orchestrator
        self.db = database_manager
        self.models = {}
    
    def generate_predictions(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Generate predictions using ML models"""
        if not ML_AVAILABLE:
            return {'error': 'Machine learning libraries not available'}
        
        try:
            # Get historical data
            historical_data = self._prepare_historical_data(start_time, end_time)
            
            if len(historical_data) < 10:  # Need minimum data points
                return {'error': 'Insufficient historical data for predictions'}
            
            # Train models and make predictions
            load_prediction = self._predict_load(historical_data)
            scaling_recommendation = self._predict_scaling_needs(historical_data)
            
            return {
                'next_24h_load': load_prediction.get('predicted_load', 0),
                'scaling_recommendation': scaling_recommendation,
                'optimization_potential': 0.15,  # 15% optimization potential
                'confidence': load_prediction.get('confidence', 0),
                'recommendations': [
                    f"Expected load increase of {load_prediction.get('predicted_load', 0):.1%} in next 24h",
                    f"Scaling recommendation: {scaling_recommendation}",
                    "Consider implementing predictive auto-scaling"
                ]
            }
            
        except Exception as e:
            logger.error(f"Prediction error: {e}")
            return {'error': str(e)}
    
    def _prepare_historical_data(self, start_time: datetime, end_time: datetime) -> pd.DataFrame:
        """Prepare historical data for ML models"""
        # This would typically get comprehensive historical metrics
        # For now, create sample data
        
        data = []
        current = start_time
        
        while current < end_time:
            # Sample data with some patterns
            hour = current.hour
            day_of_week = current.weekday()
            
            # Simulate usage patterns
            base_load = 0.4
            if 9 <= hour <= 17:  # Business hours
                base_load += 0.3
            if day_of_week < 5:  # Weekdays
                base_load += 0.2
            
            # Add some randomness
            load = base_load + np.random.normal(0, 0.1)
            load = max(0.1, min(0.9, load))  # Clamp between 0.1 and 0.9
            
            data.append({
                'timestamp': current,
                'hour': hour,
                'day_of_week': day_of_week,
                'load': load,
                'tasks_per_hour': int(load * 100),
                'active_nodes': len(self.orchestrator.nodes)
            })
            
            current += timedelta(hours=1)
        
        return pd.DataFrame(data)
    
    def _predict_load(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Predict future load using time series analysis"""
        # Prepare features
        features = ['hour', 'day_of_week', 'active_nodes']
        X = data[features]
        y = data['load']
        
        # Train model
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        
        # Predict next 24 hours
        future_predictions = []
        current_time = data['timestamp'].max()
        
        for i in range(24):
            future_time = current_time + timedelta(hours=i+1)
            future_features = [
                future_time.hour,
                future_time.weekday(),
                len(self.orchestrator.nodes)
            ]
            
            prediction = model.predict([future_features])[0]
            future_predictions.append(prediction)
        
        avg_predicted_load = np.mean(future_predictions)
        confidence = model.score(X, y)  # R² score as confidence measure
        
        return {
            'predicted_load': avg_predicted_load,
            'confidence': confidence,
            'hourly_predictions': future_predictions
        }
    
    def _predict_scaling_needs(self, data: pd.DataFrame) -> str:
        """Predict scaling needs"""
        current_load = data['load'].iloc[-1]
        trend = np.polyfit(range(len(data)), data['load'], 1)[0]
        
        if trend > 0.01 and current_load > 0.7:
            return "Scale up recommended"
        elif trend < -0.01 and current_load < 0.3:
            return "Scale down possible"
        else:
            return "No scaling needed"